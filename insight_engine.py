import os
import feedparser
import requests
import yfinance as yf
import json
from datetime import datetime
import pytz
from google import genai

# [ì„¤ì •]
REC_FILE = 'recommendations.json'
HISTORY_FILE = 'history.json'

def get_market_data():
    """ì£¼ìš” ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘"""
    indices = {"KOSPI": "^KS11", "KOSDAQ": "^KQ11", "S&P500": "^GSPC", "NASDAQ": "^IXIC"}
    result = {}
    now_utc = datetime.now(pytz.utc)
    for name, ticker in indices.items():
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="2d")
            if not hist.empty and len(hist) >= 2:
                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2]
                change = ((current - prev) / prev) * 100
                if name in ["KOSPI", "KOSDAQ"]:
                    kst = now_utc.astimezone(pytz.timezone('Asia/Seoul'))
                    is_open = kst.weekday() < 5 and 9 <= kst.hour < 16
                else:
                    est = now_utc.astimezone(pytz.timezone('US/Eastern'))
                    is_open = est.weekday() < 5 and 9 <= est.hour < 17
                result[name] = {"price": round(current, 2), "change": round(change, 2), "status": "ğŸŸ¢" if is_open else "âšª"}
        except: continue
    return result

def verify_past():
    """ì–´ì œ ì¶”ì²œ ì¢…ëª©ì˜ ì˜¤ëŠ˜ ìˆ˜ìµë¥  í™•ì¸"""
    ticker_map = {"ì‚¼ì„±ì „ì": "005930.KS", "SKí•˜ì´ë‹‰ìŠ¤": "000660.KS", "NAVER": "035420.KS", "ì¹´ì¹´ì˜¤": "035720.KS", "í˜„ëŒ€ì°¨": "005380.KS"}
    try:
        if not os.path.exists(REC_FILE): return []
        with open(REC_FILE, 'r', encoding='utf-8') as f:
            old_data = json.load(f)
            past_tickers = old_data.get('tickers', [])
            results = []
            for t in past_tickers:
                clean_t = ticker_map.get(t, t)
                if '(' in clean_t: clean_t = clean_t.split('(')[-1].replace(')', '')
                if clean_t.isdigit() and len(clean_t) == 6: clean_t += ".KS"
                try:
                    s = yf.Ticker(clean_t)
                    h = s.history(period="2d")
                    if not h.empty and len(h) >= 2:
                        c = ((h['Close'].iloc[-1] - h['Close'].iloc[-2]) / h['Close'].iloc[-2]) * 100
                        results.append({"ticker": t.split('(')[0], "change": round(c, 2)})
                except: continue
            return results
    except: return []

def fetch_global_news():
    """ê¸€ë¡œë²Œ ê²½ì œ ë‰´ìŠ¤ ìˆ˜ì§‘ ë° íŠ¹ìˆ˜ë¬¸ì ì •ì œ"""
    feeds = [
        "https://news.google.com/rss/headlines/section/topic/BUSINESS?hl=ko&gl=KR",
        "https://news.google.com/rss/headlines/section/topic/BUSINESS?hl=en-US&gl=US"
    ]
    news_list = []
    for url in feeds:
        try:
            f = feedparser.parse(url)
            for entry in f.entries[:5]:
                # JSON íŒŒì‹± ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ë”°ì˜´í‘œ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
                clean_title = entry.title.replace('"', "'").replace('\\', '')
                news_list.append({"title": clean_title, "link": entry.link})
        except: continue
    return news_list

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
try:
    client = genai.Client(api_key=os.environ["GEMINI_API_KEY"])
    market_info = get_market_data()
    past_results = verify_past()
    news_data = fetch_global_news()

    # AI í”„ë¡¬í”„íŠ¸ - ë‰´ìŠ¤ ë§í¬ ë³´ì¡´ì„ ìœ„í•´ ë” ì—„ê²©í•œ êµ¬ì¡° ìš”ì²­
    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ íˆ¬ì ë¦¬í¬íŠ¸ë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
    
    1. ì›ì²œ ë‰´ìŠ¤ ë°ì´í„°: {news_data}
    2. ê³¼ê±° ì¢…ëª© ì„±ì : {past_results}

    [ì¡°ê±´]
    - news_headlines ë¦¬ìŠ¤íŠ¸ì— ìœ„ì—ì„œ ì œê³µí•œ ë‰´ìŠ¤ ë°ì´í„°ì˜ ì œëª©ê³¼ ë§í¬ë¥¼ ìµœì†Œ 5ê°œ ì´ìƒ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
    - tickersì—ëŠ” ì˜¤ëŠ˜ì˜ ì¶”ì²œ ì¢…ëª© 3ê°œë¥¼ ë„£ìœ¼ì„¸ìš”.
    - ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

    {{
      "summary": "ì‹œì¥ ìƒí™©ì— ëŒ€í•œ 3ë¬¸ì¥ ìš”ì•½",
      "news_headlines": [
        {{"title": "ë‰´ìŠ¤ ì œëª©", "link": "ë‰´ìŠ¤ ë§í¬"}}
      ],
      "tickers": ["ì¢…ëª©1", "ì¢…ëª©2", "ì¢…ëª©3"],
      "reason": "ì¶”ì²œ ì‚¬ìœ  ë° ì „ëµ"
    }}
    """

    response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    json_text = response.text.strip().replace('```json', '').replace('```', '')
    ai_data = json.loads(json_text)

    # ìµœì¢… ë°ì´í„° êµ¬ì„±
    final_data = {
        "date": datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M'),
        "market_info": market_info,
        "past_results": past_results,
        **ai_data
    }

    # í˜„ì¬ ë¦¬í¬íŠ¸ ì €ì¥ (recommendations.json)
    with open(REC_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    # ëˆ„ì  ê¸°ë¡ ì €ì¥ (history.json)
    history = []
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                history = json.load(f)
        except: history = []
    
    # ì¤‘ë³µ ê¸°ë¡ ë°©ì§€ë¥¼ ìœ„í•´ ë‚ ì§œê°€ ë‹¤ë¥¸ ê²½ìš°ë§Œ ì¶”ê°€í•˜ê±°ë‚˜ ë§ˆì§€ë§‰ ê¸°ë¡ ì—…ë°ì´íŠ¸
    history.append({
        "date": final_data["date"],
        "performance": past_results,
        "predictions": ai_data["tickers"]
    })
    
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history[-30:], f, ensure_ascii=False, indent=2)

    print("âœ… ë°ì´í„° ìˆ˜ì§‘ ë° ë¶„ì„ ì™„ë£Œ")

except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
