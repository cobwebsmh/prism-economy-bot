import os
import feedparser
import google.generativeai as genai
import requests
import yfinance as yf
import json
import re
from datetime import datetime

# ì„¤ì •ê°’
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
MODEL_NAME = 'gemini-2.5-flash'
REC_FILE = 'recommendations.json'

def send_telegram_message(message):
    """ê¸€ì ìˆ˜ ì œí•œì„ ê³ ë ¤í•˜ì—¬ ë©”ì‹œì§€ ì „ì†¡"""
    url = f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage"
    # ì•ˆì „í•˜ê²Œ 3800ìì—ì„œ ìë¦„
    if len(message) > 3800:
        message = message[:3800] + "\n\n...(ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ì–´ ì¤‘ëµë˜ì—ˆìŠµë‹ˆë‹¤)"
    
    payload = {"chat_id": TELEGRAM_CHAT_ID, "text": message, "parse_mode": "Markdown"}
    try:
        requests.post(url, json=payload)
    except Exception as e:
        print(f"ì „ì†¡ ì˜¤ë¥˜: {e}")

def get_performance_report():
    if not os.path.exists(REC_FILE):
        return "ğŸ†• *[ì •í•©ì„± ê²€ì¦]*: ì²« ê¸°ë¡ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n\n"
    
    try:
        with open(REC_FILE, 'r') as f:
            data = json.load(f)
        
        last_date = data.get('date', 'ì•Œ ìˆ˜ ì—†ìŒ')
        last_recs = data.get('tickers', [])
        
        report = f"ğŸ¯ *[{last_date}] ì¶”ì²œ ì¢…ëª© ì„±ì í‘œ*\n"
        for t in last_recs:
            try:
                stock = yf.Ticker(t)
                hist = stock.history(period="2d")
                if len(hist) >= 2:
                    change = ((hist['Close'].iloc[-1] - hist['Close'].iloc[-2]) / hist['Close'].iloc[-2]) * 100
                    emoji = "âœ…" if change > 0 else "âŒ"
                    report += f"- {t}: {change:+.2f}% {emoji}\n"
            except:
                report += f"- {t}: ë°ì´í„° í™•ì¸ ë¶ˆê°€\n"
        return report + "\n---\n"
    except:
        return ""

def run_analysis():
    print("ê¸€ë¡œë²Œ ì¸ì‚¬ì´íŠ¸ ì—”ì§„ ê°€ë™...")
    accuracy_report = get_performance_report()
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    kr_url = "https://news.google.com/rss/headlines/section/topic/BUSINESS?hl=ko&gl=KR&ceid=KR:ko"
    us_url = "https://news.google.com/rss/headlines/section/topic/BUSINESS?hl=en-US&gl=US&ceid=US:en"
    news_combined = [e.title for e in feedparser.parse(kr_url).entries[:10]] + \
                    [e.title for e in feedparser.parse(us_url).entries[:10]]
    news_text = "\n".join(news_combined)

    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
    
    # í”„ë¡¬í”„íŠ¸ë¥¼ ë” ëª…í™•í•˜ê²Œ ìˆ˜ì •
    prompt = f"""
    ë‹¹ì‹ ì€ ê¸€ë¡œë²Œ í—¤ì§€í€ë“œ ì „ëµê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë‰´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    
    [ë°ì´í„°]:
    {news_text}

    [ì‘ì„± ê·œì¹™]:
    1. í•µì‹¬ íŠ¸ë Œë“œ 3ê°€ì§€ë¥¼ ìš”ì•½í•  ê²ƒ.
    2. ì˜¤ëŠ˜ ê°€ì¥ í° ìƒìŠ¹ì´ ê¸°ëŒ€ë˜ëŠ” ì¢…ëª© 3ê°œë¥¼ 'ìˆœìœ„. ì¢…ëª©ëª…(í‹°ì»¤)' í˜•ì‹ìœ¼ë¡œ ì¶”ì²œí•  ê²ƒ.
    3. ë°˜ë“œì‹œ ë§ˆì§€ë§‰ ì¤„ì— ë‹¤ìŒ í˜•ì‹ì„ í¬í•¨í•  ê²ƒ: TICKERS: ["í‹°ì»¤1", "í‹°ì»¤2", "í‹°ì»¤3"]

    í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    """

    # 4. í‹°ì»¤ ì¶”ì¶œ ë° ë‰´ìŠ¤ ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
    try:
        import re
        match = re.search(r'TICKERS:\s*(\[.*?\])', response.text)
        if match:
            tickers = json.loads(match.group(1))
            
            # ëŒ€ì‹œë³´ë“œìš© ë°ì´í„° êµ¬ì¡° ìƒì„±
            dashboard_data = {
                'date': datetime.now().strftime('%Y-%m-%d'),
                'tickers': tickers,
                'summary': response.text.split("ì£¼ìš” ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„:")[0].replace("##", "").strip(), # ìš”ì•½ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                'news_list': news_combined[:10] # ìˆ˜ì§‘í–ˆë˜ ë‰´ìŠ¤ 10ê°œ í¬í•¨
            }
            
            with open(REC_FILE, 'w', encoding='utf-8') as f:
                json.dump(dashboard_data, f, ensure_ascii=False, indent=4)
    except Exception as e:
        print(f"ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    run_analysis()
