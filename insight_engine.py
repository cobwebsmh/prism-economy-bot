import os
import feedparser
import requests
import yfinance as yf
import json
from datetime import datetime
import pytz
from google import genai

# [ì„¤ì •]
REC_FILE = 'recommendations.json'
HISTORY_FILE = 'history.json'

def get_market_data():
    """ì£¼ìš” ì‹œì¥ ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ë° 'ë‚ ì§œ ê¸°ë°˜' ê°œì¥ ì—¬ë¶€ íŒë‹¨"""
    indices = {"KOSPI": "^KS11", "KOSDAQ": "^KQ11", "S&P500": "^GSPC", "NASDAQ": "^IXIC"}
    result = {}
    now_utc = datetime.now(pytz.utc)
    
    for name, ticker in indices.items():
        try:
            stock = yf.Ticker(ticker)
            # ì—°íœ´ ê¸°ê°„ì„ ê³ ë ¤í•˜ì—¬ 5ì¼ì¹˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´
            hist = stock.history(period="5d")
            if not hist.empty and len(hist) >= 1:
                current_day = hist.iloc[-1]
                prev_day = hist.iloc[-2] if len(hist) >= 2 else current_day
                
                current_price = current_day['Close']
                prev_price = prev_day['Close']
                change_pct = ((current_price - prev_price) / prev_price) * 100
                
                # í•µì‹¬: ë°ì´í„°ì˜ ë‚ ì§œì™€ í˜„ì¬ ë‚ ì§œë¥¼ ë¹„êµí•˜ì—¬ íœ´ì¥ ì—¬ë¶€ íŒë‹¨
                if name in ["KOSPI", "KOSDAQ"]:
                    kst_now = now_utc.astimezone(pytz.timezone('Asia/Seoul'))
                    data_date = hist.index[-1].astimezone(pytz.timezone('Asia/Seoul')).date()
                    is_today = (data_date == kst_now.date())
                    # í•œêµ­ ì‹œê°„ ê¸°ì¤€ 9ì‹œ~16ì‹œ & ì˜¤ëŠ˜ ë°ì´í„° & ê±°ë˜ëŸ‰ ì¡´ì¬
                    is_open = is_today and (9 <= kst_now.hour < 16) and (current_day['Volume'] > 0)
                else:
                    est_now = now_utc.astimezone(pytz.timezone('US/Eastern'))
                    data_date_us = hist.index[-1].astimezone(pytz.timezone('US/Eastern')).date()
                    is_today_us = (data_date_us == est_now.date())
                    # ë¯¸êµ­ ì‹œê°„ ê¸°ì¤€ 9ì‹œ~17ì‹œ & ì˜¤ëŠ˜ ë°ì´í„° & ê±°ë˜ëŸ‰ ì¡´ì¬
                    is_open = is_today_us and (9 <= est_now.hour < 17) and (current_day['Volume'] > 0)
                
                result[name] = {
                    "price": round(current_price, 2), 
                    "change": round(change_pct, 2), 
                    "is_open": is_open,
                    "status": "ğŸŸ¢" if is_open else "âšª"
                }
        except Exception as e:
            print(f"Error fetching {name}: {e}")
            continue
    return result

def verify_past():
    """ì–´ì œ ì¶”ì²œ ì¢…ëª©ì˜ ì˜¤ëŠ˜ ìˆ˜ìµë¥  í™•ì¸ (íœ´ì¥ì¼ ìˆ˜ìµë¥  0% ì²˜ë¦¬)"""
    ticker_map = {
        "ì‚¼ì„±ì „ì": "005930.KS", "SKí•˜ì´ë‹‰ìŠ¤": "000660.KS", "NAVER": "035420.KS", 
        "ì¹´ì¹´ì˜¤": "035720.KS", "í˜„ëŒ€ì°¨": "005380.KS", "NVDA": "NVDA", "AAPL": "AAPL", "TSLA": "TSLA"
    }
    try:
        if not os.path.exists(REC_FILE): return []
        with open(REC_FILE, 'r', encoding='utf-8') as f:
            old_data = json.load(f)
            past_tickers = old_data.get('tickers', [])
            results = []
            for t in past_tickers:
                clean_t = ticker_map.get(t, t)
                if clean_t.isdigit() and len(clean_t) == 6: clean_t += ".KS"
                
                try:
                    s = yf.Ticker(clean_t)
                    h = s.history(period="2d")
                    if not h.empty and len(h) >= 2:
                        # ì˜¤ëŠ˜ ê±°ë˜ëŸ‰ì´ ì—†ìœ¼ë©´ ìˆ˜ìµë¥  ê³„ì‚° ì œì™¸ (0.0ìœ¼ë¡œ í‘œì‹œ)
                        if h['Volume'].iloc[-1] == 0:
                            results.append({"ticker": t, "change": 0.0})
                        else:
                            c = ((h['Close'].iloc[-1] - h['Close'].iloc[-2]) / h['Close'].iloc[-2]) * 100
                            results.append({"ticker": t, "change": round(c, 2)})
                except: continue
            return results
    except: return []

def fetch_global_news():
    """ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘"""
    feeds = [
        "https://news.google.com/rss/headlines/section/topic/BUSINESS?hl=ko&gl=KR",
        "https://news.google.com/rss/headlines/section/topic/BUSINESS?hl=en-US&gl=US"
    ]
    news_list = []
    for url in feeds:
        try:
            f = feedparser.parse(url)
            for entry in f.entries[:5]:
                news_list.append({"title": entry.title.replace('"', "'"), "link": entry.link})
        except: continue
    return news_list

# --- ë©”ì¸ ì‹¤í–‰ ---
try:
    client = genai.Client(api_key=os.environ["GEMINI_API_KEY"])
    market_info = get_market_data()
    past_results = verify_past()
    news_data = fetch_global_news()

    kr_status = "ê°œì¥" if market_info.get("KOSPI", {}).get("is_open") else "íœ´ì¥"
    us_status = "ê°œì¥" if market_info.get("S&P500", {}).get("is_open") else "íœ´ì¥"

    prompt = f"""
    ë‹¹ì‹ ì€ í”„ë¦¬ì¦˜(Prism) AI ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤.
    í˜„ì¬ ì‹œì¥ ìƒíƒœ: í•œêµ­({kr_status}), ë¯¸êµ­({us_status})
    ì›ì²œ ë°ì´í„°: ë‰´ìŠ¤({news_data}), ê³¼ê±°ì„±ì ({past_results})

    [ì§€ì¹¨]
    1. í˜„ì¬ 'ê°œì¥' ìƒíƒœì¸ ì‹œì¥ì˜ ì¢…ëª©ì„ ìµœìš°ì„ ì ìœ¼ë¡œ ì¶”ì²œí•˜ì„¸ìš”. 
    2. ì–‘ìª½ ëª¨ë‘ ê°œì¥ ì‹œ í•œêµ­ê³¼ ë¯¸êµ­ ì¢…ëª©ì„ ì ì ˆíˆ ì„ì–´ì„œ ì¶”ì²œí•˜ì„¸ìš”.
    3. í•œêµ­ì´ íœ´ì¥ì¼ ê²½ìš° ë¯¸êµ­ ì‹œì¥ ìœ„ì£¼ë¡œ, ë¯¸êµ­ì´ íœ´ì¥ì¼ ê²½ìš° í•œêµ­ ì‹œì¥ ìœ„ì£¼ë¡œ ë¶„ì„í•˜ì„¸ìš”.
    4. ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.

    {{
      "summary": "ì‹œì¥ ìƒí™© 3ë¬¸ì¥ ìš”ì•½",
      "news_headlines": [ {{"title": "ë‰´ìŠ¤ì œëª©", "link": "ë§í¬"}} ],
      "tickers": ["ì¢…ëª©ëª…1", "ì¢…ëª©ëª…2", "ì¢…ëª©ëª…3"],
      "reason": "ì¶”ì²œ ì‚¬ìœ  (ì–´ëŠ ì‹œì¥ì´ íœ´ì¥ì´ë¼ ì–´ë–¤ ì „ëµì„ ì·¨í–ˆëŠ”ì§€ í¬í•¨)"
    }}
    """

    response = client.models.generate_content(model="gemini-2.0-flash", contents=prompt)
    ai_data = json.loads(response.text.strip().replace('```json', '').replace('```', ''))

    final_data = {
        "date": datetime.now(pytz.timezone('Asia/Seoul')).strftime('%Y-%m-%d %H:%M'),
        "market_info": market_info,
        "past_results": past_results,
        **ai_data
    }

    with open(REC_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=2)

    # íˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (íœ´ì¥ì¼ ì œì™¸)
    history = []
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
            history = json.load(f)
    
    history.append({
        "date": final_data["date"],
        "performance": [r for r in past_results if r['change'] != 0],
        "predictions": ai_data["tickers"]
    })
    
    with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
        json.dump(history[-30:], f, ensure_ascii=False, indent=2)

    print(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ (KR:{kr_status} / US:{us_status})")

except Exception as e:
    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
